---
title: "Note of data science training EP 10: Cluster – collecting and clustering"
layout: post
description: How to find the lifestyle of 100 customers in each terms e.g. bookworms, sport guys, and shoppers.
date: 2020-06-08 00:00:00 +0200
categories: [data, data science]
tags: [Scikit-learn, clustering, DBSCAN, K-means, OPTICS, metrics, Python]
image:
  path: ../assets/img/features/bilal-o-ljXekphwr40-unsplash.jpg
  alt: Unsplash / Bilal O.
  caption: <a href="https://unsplash.com/photos/blue-and-pink-water-droplets-ljXekphwr40">Unsplash / Bilal O.</a>
---

[expand-series]

  1. [Note of data science training EP 1: Intro – unboxing]({% post_url 2020-01-12-data-sci-1 %})
  1. [Note of data science training EP 2: Pandas & Matplotlib – from a thousand mile above]({% post_url 2020-01-24-data-sci-2 %})
  1. [Note of data science training EP 3: Matplotlib & Seaborn – Luxury visualization]({% post_url 2020-01-24-data-sci-3 %})
  1. [Note of data science training EP 4: Scikit-learn & Linear Regression – Linear trending]({% post_url 2020-02-17-data-sci-4 %})
  1. [Note of data science training EP 5: Logistic Regression & Dummy Classifier – Divide and Predict]({% post_url 2020-02-27-data-sci-5 %})
  1. [Note of data science training EP 6: Decision Tree – At a point of distraction]({% post_url 2020-03-02-data-sci-6 %})
  1. [Note of data science training EP 7: Metrics – It is qualified]({% post_url 2020-03-12-data-sci-7 %})
  1. [Note of data science training EP 8: Ensemble – Avenger's ensemble]({% post_url 2020-04-15-data-sci-8 %})
  1. [Note of data science training EP 9: NetworkX – Map of Marauder in real world]({% post_url 2020-05-14-data-sci-9 %})
  1. Note of data science training EP 10: Cluster – collecting and clustering
  1. [Note of data science training EP 11: NLP & Spacy – Languages are borderless]({% post_url 2020-07-07-data-sci-11 %})
  1. [Note of data science training EP 12: skimage – Look out carefully]({% post_url 2020-07-27-data-sci-12 %})
  1. [Note of data science training EP 13: Regularization – make it regular with Regularization]({% post_url 2020-09-03-data-sci-13 %})
  1. [Note of data science training EP 14 END – Data scientists did their mistakes]({% post_url 2020-09-19-data-sci-14 %})

[/expand-series]

One of the classic problem for data scientists is clustering or grouping. For example, we have to find the lifestyle of 100 customers in each terms e.g. bookworms, sport guys, and shoppers. How can we do?

---

## Clustering

For that problem, this is introduced, the module `sklearn.cluster`.

![import](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-20.49.47.png)

---

## Preparing

This time, we have a dataset named "make_blobs" from sci-kit learn dataset.

![make blob](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-20.49.31.png)

Try a simple scatter graph and there are 3 groups actually, aren't they?

![plt](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-20.49.39.png)

---

## DBSCAN

**DBSCAN** stands for "**D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise". It works like these.

1. Give _x_ as a distance.
1. Pick _y_ dots and find the core point among those dots.
1. Find other dots within _x_ radius from the core point of _y_ dots. If any, create a group then update the core point of the group.
1. Finished when all dots has its own group.

Now we start from creating a DBSCAN object with 2 parameters:

- `eps` (epsilon) as the distance _x_.
- `min_samples` as the minimum dots or the number _y_.

After that, we use `.fit_predict()` and the result is in `.labels_`.

Here we use `pd.unique()` to check all groups in the model.

![DBSCAN](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-20.50.06.png)

Change `eps` and `min_samples` and we can distinguish the result.

![update params](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.02.07.png)

---

## K-means

K-means is the popular one as it is easy to use. This requires a number of group and it's done.

Firstly, we want 3 groups and we have 3 groups now.

![k-means](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.02.18.png)

Use `.cluster_centers_` to find the center of each group.

![cluster center](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.02.52.png)

Let's try to find 5 groups.

![k-means 5 groups](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.02.59.png)

Interesting.

![cluster center 5 groups](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.03.07.png)

---

## OPTICS

The last one is Optics standing for "**O**rdering **P**oints **T**o **I**dentify the **C**lustering **S**tructure".

This is similar to DBSCAN but not requires epsilon. It is suit for large datasets and trade-off for long run time.

![optics](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.03.14.png)

Try change `min_samples`.

![optics change param](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.03.22.png)

---

## Metrics measurement

Now it's assessment time. There are 3 main scores for the clustering models.

1. **Silhouette score**  
  Determines distances within a cluster and between clusters.  
  Best at 1 and worst at -1.
1. **Davies-Bouldin score**  
  Calculates dispersion of each cluster and distance between clusters.  
  Best at 0 and the higher is the worse.
1. **Calinski-Harabasz Score**  
  Find a ratio between dispersion in each cluster and between-cluster.  
  The higher is the better.

```py
from sklearn import metrics

# Silhouette score
metrics.silhouette_score(dataframe, clustering.labels_)

# Davies-Bouldin score
metrics.davies_bouldin_score(dataframe, clustering.labels_)

# Calinski-Harabasz Score
metrics.calinski_harabasz_score(dataframe, clustering.labels_)
```

![metrics](https://bluebirzdotnet.s3.ap-southeast-1.amazonaws.com/note-data-science-eps/ep-10/Screen-Shot-2020-06-06-at-21.17.58.png)

---

Hope this is useful as the grouping problems are much popular in many industries.

Let's see what's next.

See ya~

---

## References

- [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)
- [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- [OPTICS](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html)
